---
title: Java面试题
prev:
  text: Java面试题
  link: /questions/Java面试题.md
next:
  text: 框架中间件面试题
  link: /questions/框架中间件面试题.md
---
::: info
&#8195;&#8195;面试题话术汇总，方便面试复习
:::
[[toc]]

***
## JVM原理
### 请简单说一下类的加载过程？
&#8195;&#8195;类加载主要分为加载、验证、准备、解析和初始化阶段。
1. 在加载之前，java文件会被编译打包成class文件，此时大部分final修饰的静态常量分配内存，放入方法区的常量池，同时进行泛型擦除。
2. 加载：JVM使用类加载器加载类，读入字节码文件，生成对象存入堆内存。
3. 验证：验证字节码、文件格式、元数据、符号引用等。
4. 准备：静态变量在方法区分配内存，静态变量赋默认值。
5. 解析：执行静态链接，即将常量池中的符号引用变为直接引用。
6. 初始化：静态变量赋初始值，执行静态代码块。注意，只有主动使用类时，才会执行初始化，也就是以下几种情况：
   - new一个对象
   - 访问非final修饰的静态变量或者执行静态方法
   - 反射调用
   - main()方法启动时初始化
   - default方法要在接口实现实例化前初始化
   - 父类没有初始化需要先初始化父类
7. 初始化后就可以使用对象了，类(class)被加载到方法区后保存的信息有以下：
   - 运行时常量池
   - 类型信息
   - 字段信息
   - 方法信息
   - 类加载器的引用
   - Class对象的引用
8. 对象使用完成后会被回收，其中BootstrapClassLoader、ExtClassLoader、AppClassLoader加载的类不会被卸载，只会将实例化后的对象GC，自定义加载器加载的类在使用完成后，类信息也会被卸载。

### JVM提供了哪些类加载器？类加载器如何初始化的？
&#8195;&#8195;JVM提供了三种类加载器：BootstrapClassLoader、ExtClassLoader、AppClassLoader。
- BootstrapClassLoader：加载JAVA_HOME/lib下的类
- ExtClassLoader：加载JAVA_HOME/ext/lib下的类
- AppClassLoader：加载CLASS_PATH下的类
### 如何自定义类加载？
1. 继承ClassLoader。
2. 重写findClass()方法并调用definiteClass()方法实现类加载过程。
3. 重写loadClass()方法实现向上委托机制。


### 什么是双亲委派机制？
&#8195;&#8195;所谓的双亲委派机制，就是JVM避免类被重复加载和防止核心类库被外部类篡改的一种机制：
1. 当我们有自定义类加载器时，在加载类时，首先判断是否已经加载过，如果加载过则直接返回；否则会调用loadClass()方法调用上一级的类加载器，也就是AppClassLoader。
2. AppClassLoader也会首先检查自己的范围内是否加载了该类，如果加载过直接返回；否则调用loadClass()方法调用上一级类加载器，也就是ExtClassLoader。
3. ExtClassLoader同样先检查自己的范围内是否加载了该类，如果加载了直接返回；否则调用loadClass()方法调用上一级的类加载器BootstrapClassLoader。
4. BootstrapClassLoader检查是否已经加载了该类，如果加载了，直接返回；否则判断是否是属于该类加载器的加载范围，如果属于范围内的类，则进行加载，否则调用findClass()委托下一级进行加载。
5. ExtClassLoader判断该类是否是自己的加载范围内的类，如果是进行加载；否则调用findClass委托下一级类加载器进行加载。
6. AppClassLoader判断该类是否属于自己的加载范围，如果是则进行加载；否则调用findClass()委托下一级类加载器进行加载。
7. 自定义类加载器加载类。

### 如何打破双亲委派机制？Tomcat是如何打破双亲委派机制的？
&#8195;&#8195;通过重写loadClass()方法直接加载字节码文件，而不是委托parent进行加载，就可以打破双亲委派机制。

&#8195;&#8195;Tomcat每一个WebApp都应该是隔离的，因此不能混淆，所以每个WebApp之间的类加载器是打破双亲委派的，只加载自己容器的类。具体的实现就是Tomcat容器自己有所需要的公共类库，提供了一个类加载器用来加载，WebApp之间共享。每个WebApp又有自己独有的类加载器，打破了双亲委派，只加载自己WebApp下所使用到的类。

### 什么是Java的SPI机制？如何实现？
&#8195;&#8195;Java的SPI机制是一种服务发现机制，可以通过读取ClassPath下META-INFO/services文件，自动加载接口的实现类，每次会把所有配置的类都加载上，比较消耗资源。

&#8195;&#8195;Java的SPI机制的实现，依赖于ServiceLoader，ServiceLoader通过一个懒加载的扫描器来扫描META-INFO/services下的文件名并且转换为类的全限定名，然后通过反射机制加载类。

### 什么是JVM的内存模型？都有哪几部分组成？各有什么作用？
&#8195;&#8195;Java虚拟机由类加载子系统、运行时数据区和字节码执行引擎组成。其中类加载子系统负责进行编译和将字节码文件加载为类，加载后的class文件被存储到运行时数据区，字节码执行引擎执行运行时数据区的数据。

&#8195;&#8195;其中运行时数据区的内存划分就是JVM的内存模型，是一种逻辑划分，分为堆、栈、方法区、本地方法栈和程序计数器。
- 堆：线程之间共享，用于存放对象，分为年轻代和老年代，一般情况下年轻代和老年代占比为1:2，年轻代又划分为Eden区和Survivor区，Eden区和Survivor区划分比例一般是8:1:1。
- 方法栈和本地方法栈：线程独有，以方法为栈帧，一个方法执行则代表一个栈帧入栈，一个方法执行结束则代表一个栈帧出栈。本地方法栈与方法栈作用一样，区别是一个运行本地方法。栈帧内存放方法相关信息，包括：
  - 局部变量表：存放方法的局部变量，其中引用变量存放指针，引用自堆。
  - 操作数栈：存放逻辑运算的操作数。
  - 动态链接：动态链接的作用是把方法的符号引用变成直接引用，指向方法区存放的方法。
  - 方法出口：方法执行结束后应该返回的位置。
- 程序计数器：线程独有，每个方法栈有一个程序计数器，存放行号，因此又叫行号计数器，用于记录当前线程执行代码的位置。
- 方法区：线程共享，存放类的元信息、常量、静态变量、即时编译后的代码缓存等。

### 堆内存如何划分的？数据在堆内存中如何流转的？
&#8195;&#8195;JVM采用分代收集的思想管理内存，不同的垃圾回收器对堆内存的具体物理划分是不一样的，但是可以抽象为一个比较简单的逻辑划分：年轻代和老年代，年轻代又分为Eden区和Survivor区。其中默认年轻代和老年代比例是1:2，Eden区和S区比例是8:1:1。

&#8195;&#8195;Jvm中对象在堆内存中的流转过程大致如下：
1. 新的对象进入Eden区。
2. Eden区满后，minor gc，根据GC Root找到不需要进行垃圾回收的对象，放入s0区，分代年龄+1，其他对象gc掉。
3. 当Eden区再次放满后，再次触发minor GC，s0的区域也会minor GC，Eden和s0区不需要被回收的对象放入s1区，同时分代年龄+1，其他对象回收掉。
4. 重复上述过程，直到分代年龄到达默认15或者设定的阈值，挪到老年代，其中大对象直接存入老年代。
5. 当老年代满后，触发full gc，回收整个方法区、堆。
6. 如果full gc后老年代仍然是满的，触发oom。

&#8195;&#8195;其中full gc是一个stop the world的过程，因此十分消耗资源。另外，Spring的Bean、缓存、常量引用这种对象一般都是最终会长时间存在于老年代。

### Java如何创建一个对象？
1. 类加载检查：new关键字实例化一个对象时，检查指令参数是否能在方法区定位到一个类的符号引用，并且检查这个符号引用是否已经被加载、解析和初始化，如果没有则先执行类的加载过程。
2. 类加载：详见类加载的5个步骤。
3. 分配内存：类加载后，为新的对象分配内存。对象所需要的内存在类加载完成后就可以确定，这里涉及到两个问题，内存划分的方法和并发划分内存的问题：
   - 内存划分方法：
     - 默认指针碰撞，如果java堆是规整的，那么会将Java堆内存分为两部分，一部分是分配过的，一部分是未分配的，指针指向分配过的末尾，每次分配内存指针挪动对应距离即可。
     - 空闲列表：如果内存不规整，那么虚拟机就需要维护一个列表，记录哪些内存块可以使用，分配内存时将符合条件的内存分配给对象并且更新空闲列表。
   - 并发划分内存：
     - CAS：虚拟机采用CAS加上重试机制保证内存更新的原子性，以此来进行同步处理。
     - 本地线程分配缓冲区(TLAB)：为每个线程分配一定的空间，按照线程执行内存分配动作。
4. 初始化：初始化主要是完成一些默认操作，如给属性付默认值。
5. 设置对象头：给对象的对象头设置对应属性。
6. 执行对象的init方法，即按照用户的指定进行初始化。

### Java对象头的结构是什么样的？
&#8195;&#8195;对象在内存中存储分为三部分：对象头、实例数据和对齐填充。其中实例数据就是对象实例包含的相关数据信息，对齐填充是需要把对象大小填充为8的倍数，以便于CPU高效执行。

&#8195;&#8195;对象头分为两部分，一部分存储对象的运行时信息，如GC年龄分代、锁状态、线程持有的锁、偏向线程ID等等。

&#8195;&#8195;另一部分是类型指针，指向方法区中类的元数据信息。

&#8195;&#8195;由于一个Java对象指针是35位，如果不进行压缩的话，实际存储需要64位，寻址大小就不支持小内存寻址，而且会增加GC压力，因此JVM会开启指针压缩，将35位指针压缩为32位，这样就支持32G以下的内存，4G内存以下直接砍掉高位32位、32G以内4G以上使用压缩指针，32G以上使用64位的指针，因此一般堆内存不要超过32G。

### Java对象在栈内如何分配的？
&#8195;&#8195;大部分的对象是在堆内存中分配的，但是为了减少临时对象在堆内的分配数量，JVM会通过逃逸分析分析对象会不会被外部方法访问到，如果不会被外部方法访问到，那么会进行标量替换，将对象的属性替换为方法的内部属性，在栈分配空间，生命周期随着方法的执行周期。

&#8195;&#8195;其中逃逸分析和标量替换都是默认开启，可以通过启动参数控制开启或者关闭。

### Java对象在Eden区如何分配的？
&#8195;&#8195;大多数情况下，新的对象都被分配在Eden区，当Eden区没有空间可供分配时，触发young GC或者Minor GC。这里需要区分一下GC的类型：
- Minor GC/Young GC：发生在新生代，比较频繁，回收速度也比较快。
- Full GC/Major GC：发生在堆和方法区的所有区域的垃圾对象，由老年代满载触发，回收范围大，效率比Minor GC慢非常多。

&#8195;&#8195;大量的对象被存放在Eden区，Eden区存放满了后触发Minor GC，大概99%的对象都会被回收，剩余的存活对象被挪到s区，并且增加分代年龄，当下一次Eden区满后，Minor GC会同时回收Eden区和s区，并把存活的对象挪到另一片s区。

&#8195;&#8195;Eden区和Survivor区的分配比例默认是8:1:1，分配原则是尽可能使得Eden区大，S区够用即可。可以通过启动参数开启自动动态调节比例(默认开启)，也可以通过参数控制是否打印GC日志(默认打印)。

### 老年代都存放哪些对象？
&#8195;&#8195;老年代存放大对象和长期存活的对象，详见上述两个问题。

&#8195;&#8195;大对象的特点是需要大量连续的内存空间，可以通过JVM的启动参数设定大对象的大小。如果大对象超过设定的参数大小，会直接进入老年代。

&#8195;&#8195;之所以大对象会直接进入老年代，是为了避免大对象的复制操作会非常降低效率。

&#8195;&#8195;对象的分代年龄是通过对象头的对象年龄计数器来累加的，对象在正常的gc过后，如果被存留，分代年龄会被累加1，当分代年龄达到一个阈值(默认15)，会被老年代收容，进而减少被Minor GC的频率，减少复制次数。阈值可以通过参数设置。

### Java大对象在内存中如何分配？
&#8195;&#8195;大对象的特点是需要大量连续的内存空间，可以通过JVM的启动参数设定大对象的大小。如果大对象超过设定的参数大小，会直接进入老年代。

&#8195;&#8195;之所以大对象会直接进入老年代，是为了避免大对象的复制操作会非常降低效率。

### 长期存活的对象存放在哪儿？
&#8195;&#8195;对象的分代年龄是通过对象头的对象年龄计数器来累加的，对象在正常的gc过后，如果被存留，分代年龄会被累加1，当分代年龄达到一个阈值(默认15)，会被老年代收容，进而减少被Minor GC的频率，减少复制次数。阈值可以通过参数设置。

### 什么是对象的动态年龄判断机制？
&#8195;&#8195;当S区的一批对象大于当前空间的一个比例(默认50%，可以通过启动参数设置)，那么大于这批对象年龄中最大值的对象在下次GC时直接进入老年代，不用判断分代年龄阈值。对象的动态年龄判断一般发生在Minor GC时。

&#8195;&#8195;动态年龄判断是一种空间换时间的概念，但是会造成一个问题，如果很多对象的生存时间大于一次MinorGC的时间，每次都能大于空间比例阈值，那么就会造成很多的对象涌入老年代从而引发频繁Full GC，这时就需要通过更改动态年龄空间比例来避免。

### 什么是老年代空间分配的担保机制？
&#8195;&#8195;Minor GC时会计算老年代的空间，如果这个空间小于年轻代的所有对象(包括未被回收的对象)的空间之和，则会判断老年代的空间是否大于之前每一次进入老年代的的对象的平均大小，如果小于，则会直接触发Full GC。

&#8195;&#8195;这也是容易频繁触发Full GC的一个原因之一，需要通过调整空间分配比例来调优。

### JVM提供了哪些引用类型？
- 强引用：平常我们声明的对象引用都是强引用。
- 软引用：通过SoftRefrence声明，Full GC后如果没有可以释放的空间，会释放软引用。
- 弱引用：GC会直接回收。
- 虚引用：GC会直接回收。

### 如何判断一个对象是否应该被回收？
&#8195;&#8195;JVM判断一个对象是否应该被回收是通过可达性分析算法和finalize()方法完成的。

&#8195;&#8195;可达性分析算法是将GC Roots作为对象的起点，从这些节点开始向下搜索，可以找到的对象都是非垃圾对象，其实也就是GC Roots一级级引用的对象。其中可以作为GC Roots的对象有：线程栈的本地变量、静态变量、本地方法栈的变量等。

&#8195;&#8195;finalize()方法用于判定对象的最终存活，不在GC Roots树上的对象也不是非要垃圾回收，它还有一次机会，就是在finalize()方法中再次被引用，使其与GC Roots树上的对象再次关联。但是只能有一次机会，当这次执行完毕后，再次出发GC，即便方法中做了关联也会被回收。

### finalize()方法的作用是什么？
&#8195;&#8195;finalize()方法用于判定对象的最终存活，不在GC Roots树上的对象也不是非要垃圾回收，它还有一次机会，就是在finalize()方法中再次被引用，使其与GC Roots树上的对象再次关联。但是只能有一次机会，当这次执行完毕后，再次出发GC，即便方法中做了关联也会被回收。

### 如何判断一个类是无用的类？
&#8195;&#8195;类的元信息主要存放在方法区中，方法区也负责类的回收，判定方式如下：
- 该类的所有对象实例已经被回收
- 加载该类的类加载器对象也已经被回收
- 该类的Class对象没有任何地方被引用，也就是无法通过反射生成类。

### 有哪些垃圾回收算法？
- 复制算法：将内存分为两个区域，使用一片存放对象，当垃圾回收时，清理掉需要回收的对象，将存活的对象放在另一边。
- 标记-清除算法：分为两个阶段，标记和清除。标记阶段用于通过GC roots标记所有存活对象；清除阶段清除所有未被标记的对象。会有两个问题，标记阶段如果需要被清除的对象非常多，会有效率问题；清除后的内存空间不连续。
- 标记-整理算法：标记阶段与标记清除算法一致，通过GC Roots标记存活对象；标记完成后将所有存活对象移动到内存的一端，然后统一清除存活对象之后的空间。

### 常用的垃圾回收器有哪些？
&#8195;&#8195;现在比较常用的是小内存情况下的CMS、平时常用的G1、新的支持大内存的ZGC。

&#8195;&#8195;**首先是CMS垃圾回收器**，采用分代收集理论，其执行过程分为以下几个阶段：
1. 初始标记：STW，标记GC Roots和其可以直接引用到的对象
2. 并发标记：并发标记GC Roots树，进行标记
3. 重新标记：STW，修正并发标记阶段动态变化的对象标记
4. 并发清理：对没有被标记的对象进行清理
5. 并发重置：重置本次GC中的标记

&#8195;&#8195;CMS垃圾回收器采用标记-清除算法，标记过程采用的三色标记法，其原理是将对象分为黑色、灰色和白色。黑色代表已经被垃圾回收器扫描过，可达性分析是可达的。灰色表示已经被垃圾回收器扫描过，但是其树的下层还存在没有被扫描的对象。白色表示没有被扫描过。如果扫描结束后对象仍然是白色，那么说明该对象不可达，需要被回收。

&#8195;&#8195;其中在重新标记阶段，为了防止漏标，CMS采用的是增量更新的策略，即将黑色的对象作为GC Roots重新进行扫描，那么动态更新时插入到黑色的或者灰色的引用就会被再次扫描到。增量更新和原始快照都是通过读写屏障完成，读写屏障即在完成内存的读写操作的前后，插入一步操作，类似于AOP。

&#8195;&#8195;CMS垃圾回收器会争抢业务线程的资源，并且不能处理浮动垃圾，只能下次处理浮动垃圾，标记清除算法会产生大量的内存碎片(可以通过参数设置清理)。

&#8195;&#8195;CMS相关的调优参数有老年代触发FullGC的比例、GC的线程数、指定整理压缩空间的间隔等等。

&#8195;&#8195;CMS是传统的分代理论实现的垃圾回收器，会存在跨代引用的问题，CMS采用的是记忆集数据结构，避免把老年代纳入GC范围，因此只要通过记忆集查找是否有跨代引用即可。


&#8195;&#8195;**G1垃圾回收器**的内存划分与传统的垃圾回收器不同，G1虽然也沿用了跨代的理念，但是只做了逻辑划分，实际的物理划分是将内存划分为大小相等的独立区域(Region)，JVM最多可以划分2048个Region，并且可以通过参数指定Region。

&#8195;&#8195;G1依旧存在分代的理念，但是分代区域不再连续，而是指定Region的分代。默认年轻代初始比例5%(可以通过参数调整)，JVM在运行过程中会动态的增加年轻代的比例，最终占比不会超过60%(也可以调整)，Eden区和s区比例依旧是8:1:1。

&#8195;&#8195;其对象的流转过程不变，依旧符合数据在堆内存中的流转过程，不同的是大对象的存储规则：G1针对大对象会专门的分配Humorous区域，对于对象大小大于Region的50%的对象即判定为大对象，直接存入大对象块，超过Region大小的对象则会跨Region连续存放。

&#8195;&#8195;G1垃圾回收处理器的执行过程分为以下几个阶段：
1. 初始标记：STW，标记GC Roots和能够直接引用的对象
2. 并发标记：并发标记GC Roots树
3. 最终标记：STW，修正动态变化的对象状态
4. 筛选回收：首先对每个Region的回收价值进行排序，根据用户设定的GC停顿期望时间定制回收计划，然后利用复制算法进行回收，这样就不会产生内存碎片。

&#8195;&#8195;G1垃圾处理器的GC阶段也与传统的垃圾回收器不同：
- YoungGC：不再是Eden满了才回收，而是计算回收Eden时间，如果回收时间远小于期望，则会增加Eden区的Region数量。
- Mixed GC：G1独有的回收阶段，当老年代占比达到预期进行，回收所有的Young、Old、大对象，也是采用复制算法，只是回收范围更大。
- Full GC：Mixed GC后发现空间依然不足执行，采用单线程的标记-压缩-整理算法，很耗时。

&#8195;&#8195;G1垃圾回收处理器的特点是：
- 并发执行能力强，本身就是给多核大内存服务器用的，而且执行阶段允许并发执行。
- 分代概念：仍然保有分代理念。
- 空间整理：整体采用标记整理、局部采用复制算法，空间连续。
- 可停顿的预测：可以指定GC停顿间隔，减小对系统的影响，一般指定100-300ms。

&#8195;&#8195;G1垃圾回收器可以调优的参数：执行GC的并发线程数、指定分区大小、各个区的空间比例、期望gc停顿时间等等。

&#8195;&#8195;**ZGC是jdk11引入的一款可以处理大内存的垃圾回收器**，ZGC不再采用分代收集原理，但是沿用了Region的概念，将内存划分为不同大小的Region，使用读写屏障、颜色指针技术实现可以并发的标记整理算法。
- 小型Region：2M，存放小于256k的对象
- 中型Region：32M，存放大于256K小于4MB的对象
- 大型Region：容量动态化，但必须是2M的倍数，存放4M以上的大对象。大型Region的大小可能要比中型的小，实际看对象的大小。大型Region不会被ZGC重新分配。

&#8195;&#8195;ZGC的执行过程：
1. 并发标记：遍历对象图做并发标记，更新颜色指针。
2. 并发预备重分配：会根据并发标记生成一个重分配集，重分配集记录Region上的存活对象。
3. 并发重分配：将重分配集上存活的对象复制到新的Region，并且配置一个转发表，映射对象在新旧Region上的映射关系。此时如果引用了某个不需要被清理的对象，实际上是指向了重分配集，然后重分配集通过转发表映射了一个新的引用地址。
4. 并发重映射：将重分配集上的旧引用剔除，更新为新的引用，这个过程可以在下次的并发标记的过程中完成。

&#8195;&#8195;ZGC最大的问题是浮动垃圾，ZGC没有分代概念。ZGC的触发时机总共有4个：
- 定时触发：默认不适用，可以配置。
- 预热触发：最多三次，堆内存使用率达到10%、20%、30%时触发，统计GC时间为其他GC机制进行辅助。
- 分配速率触发：基于正态分布计算内存的分配速率，在内存耗尽之前触发。
- 主动触发：默认开启，判断内存距离上次GC后的增长量是否达到10%或者与上次GC的时间间隔比较，超过触发。

### 如何选择合适的垃圾回收器？
- 优先调整堆大小让JVM自行选择
- 8G以内的小服务用CMS即可
- 一般的服务使用G1即可
- 几百G以上的大内存使用ZGC，更新JVM版本

## JVM调优
### 平常都是怎么做JVM调优的(调优的思路)？
&#8195;&#8195;JVM的调优一般指的是内存优化和垃圾回收器的优化。

&#8195;&#8195;内存优化的思路是通过合理分配堆内存，使得朝生夕死的对象能都在年轻代不进入老年代，减少Full GC带来的影响，并且通过预估和计算对象内存的峰值防止OOM。

&#8195;&#8195;内存是否需要优化可以通过对JVM和系统的监控完成，JVM提供了JvisualVM这种可视化工具来监控指标，生产环境下一般不允许。也可以使用命令行进行监控，常用的命令有：
- JPS：Java程序进程号
- Jmap：查看实例的内存信息、堆的配置和使用状况、内存快照
- jstack：重要，查看死锁、CPU使用率高的线程堆栈、
- jstat：重要，查看堆内存各部分的使用量、类加载数量、堆分代内存的统计、垃圾回收的统计

&#8195;&#8195;内存优化的基本步骤一般是通过jstat间隔执行，查看年轻代对象的增长速率-->推算YGC的执行时间-->观测老年代的增长速率-->观测FullGC的频率和耗时-->进行优化。

&#8195;&#8195;垃圾回收的优化还可以通过打印gc日志。

### 如果发生CPU使用率偏高、内存偏高等具体的问题，调优的思路是什么？
&#8195;&#8195;CPU使用率偏高，一般首先考虑死循环、频繁GC、上下文切换频繁。一般思路是通过检查top命令确定CPU使用情况，然后打印jstack堆栈和GC日志，进而确定问题原因。

&#8195;&#8195;内存使用率偏高，没有OOM，可以导出Jmap的堆栈信息，查看具体的哪些实例占用偏高。

&#8195;&#8195;如果内存使用出现OOM，一般从这几个角度考虑：
- 本身内存分配和预估是否充足
- 从数据库或者其他地方一次性获取数据量过大
- 程序内短时间循环产生很多的重复对象


## Java并发
### CPU的三层缓存架构？
&#8195;&#8195;主流的CPU架构一般是采用三层缓存架构，多核CPU一般每一个核心称为一个物理核，每一个物理核有两个逻辑核、一个一级缓存和一个二级缓存组成，不同的物理核共享一个三级缓存。多CPU架构中，不同的CPU核心通过总线交互，共享内存。当一个线程运行在一个CPU上，又被调度到另一个CPU上时，就会发生上下文切换。

### 什么是用户态，什么是内核态？操作系统如何管理内存？
&#8195;&#8195;操作系统分为用户空间和内核空间两个概念，目的是为了程序运行的稳定和隔离。用户的线程只能运行在用户空间，系统的调用只能在内核空间。因此一个线程其实有两个堆栈：用户堆栈和内核堆栈。
- 内核线程：由系统内核管理，使用内核堆栈保存线程信息和线程上下文信息，线程运行在内核态(权限级别不同，运行空间不同)。
- 用户线程：用户实现和管理，线程阻塞引起进程阻塞，线程运行在用户态(权限级别不同，运行空间不同)。

&#8195;&#8195;当一个用户线程想要调用系统函数库，那么就需要从用户态切换到内核态。

### 什么是JMM内存模型？
&#8195;&#8195;JMM的内存模型是基于CPU的三层缓存架构，在逻辑上，每一个线程有一个工作内存，工作内存与线程直接交互，存放共享变量的副本。所有的线程共享一个主内存，JMM控制线程的工作内存与主内存的交互。

&#8195;&#8195;JMM对主内存和工作内存的数据同步通过八个原子性操作完成：
1. lock(锁定)：将主内存的共享变量锁定为线程独占
2. read(读入)：将独占的共享变量读入线程的工作内存
3. load(载入)：将read读入的变量放入工作内存的共享变量副本
4. use(使用)：将共享变量副本传输给执行引擎使用
5. assign(复制)：执行引擎给共享变量副本复制
6. store(存储):工作内存将共享变量传输到主内存
7. write(写入)：将工作内存传输的共享变量副本值写入到共享变量
8. unlock(解锁)：将主内存内的共享变量解除线程独占。

&#8195;&#8195;在同步时，有以下的规则：
- 不允许任何变量在没有assign，就同步回主内存中
- 任何变量必须由主内存中诞生，也就是说同步过程必须有read和load
- 一个变量同一时间只能被一个线程lock
- 执行unlock前必须先将共享变量副本同步到共享变量中

### 简述一下线程安全的三个特性？
&#8195;&#8195;线程的三个特性指的是原子性、可见性和有序性。

&#8195;&#8195;线程的**原子性**即以线程为单位，操作是原子的，是最小的执行单元。实现方式：
- 加锁：可以通过synchorized和Lock锁(ReenTrantLock)实现，即通过加锁实现串行化达到同步的目的，以保证线程执行的原子性。
- 基本类型的读和赋值本身就具有原子性。
- JUC提供的原子类通过CAS原理来保证原子性。

&#8195;&#8195;线程的**可见性**即某个线程修改了内存中共享变量的值时，共享变量的改变对所有的线程是可见的。实现方式：
- 加锁：通过串行化的同步代码，保证同一时刻只有一个线程可以访问到共享资源，以此保证可见性。
- volatile关键字：通过内存屏障实现保证共享变量修改的可见性。

&#8195;&#8195;线程的**有序性**即程序需要按照一定的顺序执行，期间会进行编译器的优化重排序、指令重排序、内存重排序等等，但是这些重排序的操作必须满足两个原则，以保证有序性：
- as-if-serial：不管编译器如何重排序，最后的执行结果不能改变。
- happens-before原则：
  - 程序顺序原则：一个线程内必须保证语义的串行，代码必须按照顺序执行。
  - 锁规则：解锁操作必须发生在下一个加锁操作之前。
  - volatile可见性：volatile修饰的关键字必须保证可见性，通过内存屏障，在共享变量每次被线程访问时，都会强迫从主内存中读取共享变量；当共享变量副本发生变化时，也都会强迫写回主内存。
  - 线程启动规则：thread.start()方法先于它的每一个动作，比如线程A修改了B中共享变量的值，那么B启动时，那么A的修改应该是对B可见的。
  - 传递性：A线程先于B线程、B线程先于C线程，那么A线程先于C线程。
  - 线程终止规则：线程的所有操作应该是先于终止，比如jion()方法的作用就是等待线程的终止后执行主线程的某些操作。
  - 线程中断原则：intercept()方法调用优先于被中断线程中检测到中断事件的发生(先中断才能检测到中断事件)。
  - 对象的终结规则：构造方法的执行优先于finalize()方法。


### volatile关键字的作用是怎样的？如何实现的？
&#8195;&#8195;volatile的作用是保证共享变量的可见性，底层通过内存屏障实现，即在共享变量每次被线程访问时，都会强迫从主内存中读取共享变量；当共享变量副本发生变化时，也都会强迫写回主内存。

&#8195;&#8195;打个比方讲就是，一个变量的地址，不仅你知道，别的线程也知道。当你的线程读写这个地址，别的线程也在做这种事，那么就需要告诉编译器，这个变量可能会同时被其他线程修改。这就是volatile关键字修饰变量的含义。

&#8195;&#8195;同样的，如果是一个在你方法里的临时变量，通常情况下只有你这个现成使用它，编译器编译时就会认为，它生成汇编代码的时候就能重复使用已经加载到cpu寄存器里的值，编译器很清楚的知道这两者的等价性，也就是cpu寄存器里的值可以重复拿来用不用管其他的线程干了什么。

&#8195;&#8195;如果说别的线程修改了这个值，其实就相当于之前读到cpu里的已经失效了。所以volatile就是告诉编译器，cpu寄存器里的值跟内存数据里的值并不能等价处理。

### 简述一下final关键字和不变性原理？
&#8195;&#8195;不变性指的是一个值一旦被初始化，那么就不能修改，引用、成员变量都不可变。final关键字就是保证不变性的，不可变的对象一定是线程安全的。

&#8195;&#8195;final修饰范围：
- 类：不可被继承
- 方法：不能被重写
- 变量：值不能被修改、引用不能被修改，但是被引用的对象可以修改。

### synchronized关键字的作用是什么？
&#8195;&#8195;synchorized是一种对象锁，是可重入的，可以修饰代码块和方法。

&#8195;&#8195;synchorized实现是通过对象的Monitor锁实现的，依赖于操作系统的互斥锁实现的。Monitor即对象头Markword中的一个字段，任何一个对象都有一个Monitor与之关联，当Monitor被一个线程持有后，Monitor就处于加锁状态。synchorized的加锁和解锁就是基于Monitor的进入和退出实现的。

&#8195;&#8195;加锁和解锁的流程是这样的：
1. 当代码执行到synchorized修饰的代码部分，执行monitorenter指令，尝试获取Monitor的所有权。
2. monitor有一个计数器，如果计数器为0，说明没有线程持有Monitor，那么该线程进入Monitor，计数器+1。
3. 如果该线程本身就持有该对象的Monitor，那么重入，即计数器再+1。
4. 如果其他线程持有该对象的Monitor，即计数器不为0，那么会阻塞，直到计数器为0。
5. 退出synchorized关键字修饰的代码时，前提条件肯定是该线程持有该对象的Monitor，然后计数器-1，重入的情况会嵌套-1，直到计数器为0表示该线程不持有锁。

&#8195;&#8195;synchorized对象锁在发生异常时会释放锁。

### synchorized锁膨胀升级过程是怎样的？
&#8195;&#8195;synchorized锁是为了解决线程安全的执行控制问题的一种机制，锁的膨胀升级是为了降低锁带来的性能消耗，因此并不会一开始就使用重量级锁。

&#8195;&#8195;锁按照级别膨胀升级，过程是单向的：无锁状态-->偏向锁-->轻量级锁-->重量级锁。
- 无锁状态：任何线程都能访问资源。
- 偏向锁：资源被一个线程竞争，就会进入偏向锁状态。大多数情况下，锁不但不会竞争，还总是会被一个线程获得，这种情况为了避免同一个线程重复获得锁的资源消耗，引入偏向锁。进入偏向锁状态的Monitor会记录偏向线程ID，当线程再次请求时，可以迅速的获取锁。
- 轻量级锁：当不是同一个线程竞争资源时，偏向锁会升级为轻量级锁，当一个线程A获取到锁，另一个线程B会通过自旋(CAS)的方式不断尝试获取锁，线程不会阻塞，从而提高性能。
- 重量级锁：当竞争的线程自旋次数达到一定的阈值，或者一个线程获取到锁，有多个线程来竞争，就会升级为重量级锁。重量级锁的特点是未获取到锁的线程都会进入等待，重量级锁的切换需要从用户态切换内核态(等待的线程交给了系统内核挂起)，成本比较高。

### synchorized为什么不再使用偏向锁？
&#8195;&#8195;java在版本15后废弃了偏向锁，其原因大概如下：
- 首先通过CPU的CAS实现的轻量级锁，本身就不需要上下文的切换就能实现加锁和解锁，在竞争不是非常激烈的情况下，消耗本身也不大；当竞争激烈时，消耗与重量级锁也差不多，因此会选择升级。
- 偏向锁的本身目的也是为了解决重量级锁需要切换上下文的问题，而且只针对一个线程获取并不存在竞争的情况。但是实际上多线程条件下这种情况本身就很少见，而且偏向锁的实现依赖于对象头的偏向锁字段和threadId字段，官网中也说了偏向锁对JVM增加了巨大的复杂性，维护成本很高。

&#8195;&#8195;综上就取消了。

### synchorized和Lock锁的区别是什么？
&#8195;&#8195;JVM提供了几种锁的实现方式，归根到底分类两种：synchorized内置锁和Lock锁。Lock锁是JVM实现锁的一个顶层接口，Lock和synchorized在功能上有很大的区别，并不能互相代替。

&#8195;&#8195;synchorized原理如上回答即可，synchorized出现异常不能释放，并且是个比较重的锁，加锁和释放锁的场景比较单一。Lock提供了几个API可以灵活的调用：
- lock：获取锁，如果被其他线程锁了，则本线程阻塞。
- tryLock：尝试获取锁，不会阻塞立即返回布尔值。
- tryLock(time)：在规定时间内获取锁，超过时间后不再阻塞。
- unlock()：解锁。

&#8195;&#8195;Lock的典型实现是ReentrantLock，其实现原理是利用AQS机制，支持中断响应、超时和尝试获取，必须显式的释放锁，可以实现公平锁和非公平锁，并且可以关联多个条件队列，具有可重入的特性。

&#8195;&#8195;在特性上的对比：
- 实现原理：ReentrantLock使用AQS机制，synchorized使用Monitor锁和轻量级锁。
- 灵活性：ReentrantLock支持中断、响应、尝试获取等等，并且要显式解锁；synchorized自动释放。
- 锁的类型：ReentrantLock支持公平锁和非公平锁；synchorized是非公平锁。
- 条件队列：ReentrantLock支持多个条件队列；synchorized只有一个条件队列。
- 是否可重入：都可重入。

### 锁的分类
&#8195;&#8195;锁根据一些分类维度可以分为：是否锁定共享资源--乐观锁和悲观锁、是否独占共享资源--共享锁和独占锁、线程是否排队等待--公平锁和非公平锁、同一个线程是否可以重入--重入锁和非重入锁、是否允许中断--中断锁和非中断锁、线程等待的状态--自旋锁和阻塞锁。

### 什么是AQS？
&#8195;&#8195;AQS通过实现一个先进先出的队列和一个资源状态来实现锁机制，核心思想是：
- 如果被请求的共享资源是空闲的，则当前线程设置为工作线程，并且将共享资源的状态设定为锁定状态。
- 如果被请求的资源是占用的，那么会将线程放入队列中，并且有一套线程阻塞和唤醒时的锁分配机制来分配线程。这套机制可以实现共享/排他、公平/非公平、重入。

### 什么是CAS原理？
&#8195;&#8195;CAS是指的Concurrent And Swap指令，是一个在并发情况下不能被打断的执行数据交换的CPU指令。其思想是假设被修改的对象当前值应该是A，如果确实是A则进行修改；如果不是A则说明该值被其他线程修改过，则不进行修改。

&#8195;&#8195;CAS有着广泛的应用场景：
- 乐观锁
- 并发容器ConcurrentHashMap使用CAS保证并发安全
- 原子类

&#8195;&#8195;CAS在Java中的核心实现是Unsafe类，通过native方法访问操作系统。其中原子类就是通过Unsafe类实现的。

&#8195;&#8195;CAS有个ABA问题，即在操作过程中，假设被修改对象应该是A，就该过程中，其他线程将A修改为B又修改为A，这时其实已经发生了修改。解决方案是乐观锁，通过设定版本号来判断修改时间线。

### 原子类如何实现的CAS？
- 原子类利用Unsafe类执行CPU的CAS命令。
- volatile关键字保证共享变量可见性。
- 使用do-while循环实现对CAS调用的自旋。

### ThreadLocal的作用是什么？ThreadLocal是如何实现的？
&#8195;&#8195;ThreadLocal是存放线程独有的变量的一个对象。常用来实现Holder。其实现原理如下：
- 每一个线程都有一个ThreadLocalMap，保存该线程的多个ThreadLocal。
- ThreadLocalMap保存在Thread对象中。
- 提供了initialValue()方法用于初始化值，提供了set、get、remove方法对变量增删改。
- 需要特别注意使用拦截器清空对象，否则会OOM。

### 如何创建线程池？有哪些参数，都有什么作用(实现原理)？
&#8195;&#8195;通过构造函数创建线程池，即new ThreadPoolExecutor。线程池的构造函数有6个核心参数：
- corePoolSize：核心线程数，核心线程数是线程池创建的会长期存活的线程数量。
- maxPoolSize：最大线程数，是线程池为了应对流量不均衡的情况，所设置的允许创建的最大线程数量，超过核心线程数的线程在任务执行完成后会休眠。
- keepAliveTime：线程存活时间，超过核心线程数的空闲线程在超过线程存活时间后会被回收。
- workQueue：工作队列，用于存放用于执行的任务。
  - SynchronousQueue：直接交换队列，容量为1，仅仅作为任务中转。
  - LinkedBlockingQueue：无界队列，容量无限大，容易OOM。
  - ArrayBlockingQueue：有界队列，需要设置队列长度。
- threadFactory：线程工厂，用于指定创建线程的工厂，默认的线程工厂创建的线程都在同一个线程组，拥有一样的优先级并且不是守护线程。
- handler：任务队列满员后的拒绝策略执行器。

&#8195;&#8195;除此之外，还可以直接声明5种线程池的实现类。

### 如何设定线程数？
&#8195;&#8195;线程池的线程数量的设定，我们一般情况下先会根据理论值估算：
- CPU密集型：主要是加解密、计算Hash、密集计算等业务，最大线程数一般设置为CPU核心数的1-2倍。
- IO密集型：增删改查、通信调用，最大线程数一般设置为CPU的10-15倍也可以。
- 核心线程数 = CPU核心数 *(1+平均等待时间/平均工作时间)
- 估算设置后，一般需要在压力测试中实测压力曲线，然后再根据曲线做修改。

### 线程池都有哪些任务拒绝策略？
&#8195;&#8195;线程池的一个参数是要求我们设置任务拒绝策略的执行器，一般任务拒绝策略会在Executor关闭时，或者Executor的线程数或者队列有边界时，达到最大边界时执行拒绝。

&#8195;&#8195;常见的拒绝策略有：
- 直接异常
- 埋没异常
- 埋没异常并且丢弃时间最久的任务
- 把任务发给提交线程的主线程处理，提供负反馈。

### 工作中都用到过哪些线程池？
&#8195;&#8195;常见的线程池的实现有5种：
- FixedThreadPool：固定线程数量的线程池，特点是
  - 核心线程数 = 最大线程数
  - keepAliveTime = 0
  - 无界队列：LinkedBlockingQueue
  - 有OOM风险
- SingleThreadExecutor：单线程线程池
  - 核心线程数 = 最大线程数 = 1
  - keepAliveTime = 0
  - 无界队列：LinkedBlockingQueue
  - 有OOM风险
- CachedThreadPool：可缓存线程池
  - corePoolSize = 0
  - maxPoolSize = MAX
  - keepAliveTime = 60s
  - 无队列：SynchronousQueue
  - 有OOM风险(线程数量过多造成)
- ScheduledThreadPool：定时任务线程池
  - 支持周期性定时任务
  - 支持延迟执行
  - 核心线程数自定义
  - 最大线程数无上限
  - keepAliveTime = 0
  - 延迟队列：DelayWorkQueue
- WorkingStealingPool：子任务线程池
  - 需要产生子任务才能使用。
  - 窃取能力：子任务有自己的队列，如果子任务完成，其他的子任务线程没有完成，那么会窃取其他线程的队列中的任务


&#8195;&#8195;声明线程池除了以上两种方法，还需要特别说明的是定时任务线程池的构造参数：
- 任务：现成具体需要执行的任务实现
- 首次执行的延迟时间
- 执行的间隔时间
- 时间单位

### 线程池的使用
&#8195;&#8195;线程池的使用主要可以从几个方面说明：线程池的控制方法、线程池内部实现的主要属性的作用、线程池的监控方法和钩子方法四个部分。

&#8195;&#8195;使用线程池一般使用其控制方法执行任务，这是线程池提供的API：
- execute(Runnable)：履行Runnabble任务
- submit(Future)：提交Future任务
- shutdown()：执行线程池关闭，并不是强制关闭，需要执行初始化关闭过程，会执行完成队列中已经存在的任务但是会拒绝新的任务
- isShutdown()：判断是否进入停止状态。
- isTerminated()：判断线程池是否真的关闭
- awaitTermination()：检测在一定时间内线程是否停止，这是个阻塞方法，会返回线程池的三种状态
  - 所有任务都关闭了
  - 等待超时
  - 等待过程被中断
- shutdownNow()：立即关闭线程池，并返回未执行任务的集合。

&#8195;&#8195;线程池内通过ctl属性的两个字段，存储线程的运行状态(runState)和线程池内的有效的线程数量(workerCount)。

&#8195;&#8195;线程池提供了方法可以监控线程池的执行状况：
- getTaskCount()：获取已经执行和未执行的任务总数
- getCompletedTaskCount()：获取已经完成的任务总数
- getPoolSize()：获取当前线程数
- getActiveCount：获取正在执行Task的线程数

&#8195;&#8195;线程池还提供了钩子方法，用于回调，在线程池的执行前后调用做前置和后置处理：
- 实现钩子方法需要继承ThreadPoolExecutor，实现自己的线程池
- 重写beforeExecutor方法
- 重写afterExecutor方法

### 线程池的状态转换

### 线程池是如何实现的？

### 线程池如何做到核心线程复用？

### 线程池如何做到核心线程不会被执行完毕？

### java线程池分配线程按照密集型分有那几类？
io密集型和cpu密集型

### 两种密集型如何分配线程数？

### 为何这么分配线程数？


### 用过哪些JUC并发工具类，都是什么作用？
- 原子类
- 线程池
- 并发流程控制器
- 锁

### 是否了解Future框架？

### 如何实现一个线程？

### todo 多线程基础

### 什么是线程安全？

### 线程安全的数据结构？

## Java高级特性
### 什么是Java的泛型机制？

### 什么是Java的注解机制？

### 什么是Java的反射机制？

### 什么是Java的SPI机制？

## Java数据结构

### HashMap原理？

### ArrayList原理？

### LinkedList原理？

### LinkedHashMap原理？

### HashMap为什么不是线程安全的？

### ConcurrentHashMap如何实现线程安全的？

## Java IO特性
### JavaIO是什么？
&#8195;&#8195;IO模型指的是用什么样的通道进行数据的发送和接收，Java支持三种网络IO模型：BIO、NIO和AIO。

### 如何理解JavaIO的装饰者模式？

### 什么是Java的BIO
&#8195;&#8195;BIO全程Blocking IO，即同步阻塞IO模型，BIO的特点是一个客户端对应一个IO线程，IO代码里的read操作和accept是阻塞操作，如果连接不做数据读写会造成线程阻塞，并且如果请求压力大的话会造成server端线程数量过多。

### 什么是Java NIO？请说一下Java NIO的多路复用原理？
&#8195;&#8195;NIO指的是Non Blocking IO，即同步非阻塞模型，server端一个线程可以处理多个请求链接。NIO模型适合连接短但是多的场景，比如聊天、弹幕、服务器通讯。

&#8195;&#8195;其原理是客户端发送的请求链接会注册到多路复用器selector上，多路复用器轮询请求链接，有IO请求的才会处理。

&#8195;&#8195;NIO有三大核心组件：
- Buffer：缓冲区，每个channel都对应一个缓冲区，buffer和channel都可以读可以写。
- Channel：每一个channel对应一个buffer缓冲区，buffer底层实现是一个数组。
- Selector：多路复用器，channel会注册到selector上，由selector根据channel读写事件的发生将其交由某个空闲线程进行处理。

&#8195;&#8195;NIO的流程是这样的：
1. Server端监听一个开放端口，client链接端口进行数据交互。
2. client会将链接放入buffer。
3. 每个buffer对应一个channel，buffer会将读写事件放入channel。
4. channel会注册到多路复用器selector上。
5. selector底层使用Linux的epoll实现的，epoll会维护一个就绪事件列表rdlist。
6. channel有读写事件就会将链接放入就绪事件列表rdlist。
7. epoll会查询就绪事件列表，如果有就绪事件，交给Selecor。
8. selector交给空闲线程处理。

### Java AIO技术是什么？
&#8195;&#8195;异步非阻塞IO，由操作系统完成后回调通知server端启动线程处理，一般适用于连接数多且链接时间长的服务。

## Java新特性
### Java 8-11的新特性？

### java 12-17的新特性？